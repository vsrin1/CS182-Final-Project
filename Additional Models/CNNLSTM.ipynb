{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"ultra_clean.csv\")\n",
    "X = []\n",
    "for text in data[\"text\"]:\n",
    "    X.append(str(text))\n",
    "y = data[[\"stars_1.0\",\"stars_2.0\",\"stars_3.0\",\"stars_4.0\",\"stars_5.0\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(X[:28000])\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(X[:28000])\n",
    "training_padded = tf.keras.preprocessing.sequence.pad_sequences(training_sequences, maxlen=200, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X[28000:])\n",
    "test_padded = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/2\n",
      "28000/28000 - 212s - loss: 1.2630 - acc: 0.5418 - val_loss: 1.0706 - val_acc: 0.6694\n",
      "Epoch 2/2\n",
      "28000/28000 - 196s - loss: 1.0697 - acc: 0.6139 - val_loss: 0.9445 - val_acc: 0.6851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14f5dea90>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model.add(tf.keras.layers.Dropout(.25))\n",
    "model.add(tf.keras.layers.Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(tf.keras.layers.LSTM(20))\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "model.add(tf.keras.layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(training_padded, y[:28000], batch_size=30, epochs=8, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.9445 - acc: 0.6851\n",
      "Test score: 0.944487778033529\n",
      "Test accuracy: 0.6851429\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_padded, y[28000:], batch_size=30)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "28000/28000 - 292s - loss: 1.3457 - acc: 0.4888 - val_loss: 1.3108 - val_acc: 0.5090\n",
      "Epoch 2/10\n",
      "28000/28000 - 291s - loss: 1.0559 - acc: 0.6142 - val_loss: 0.7948 - val_acc: 0.7053\n",
      "Epoch 3/10\n",
      "28000/28000 - 277s - loss: 0.7996 - acc: 0.6822 - val_loss: 0.7495 - val_acc: 0.7143\n",
      "Epoch 4/10\n",
      "28000/28000 - 283s - loss: 0.6874 - acc: 0.7264 - val_loss: 0.7344 - val_acc: 0.7306\n",
      "Epoch 5/10\n",
      "28000/28000 - 277s - loss: 0.6094 - acc: 0.7593 - val_loss: 0.7714 - val_acc: 0.7134\n",
      "Epoch 6/10\n",
      "28000/28000 - 281s - loss: 0.5475 - acc: 0.7866 - val_loss: 0.7741 - val_acc: 0.7140\n",
      "Epoch 7/10\n",
      "28000/28000 - 280s - loss: 0.5053 - acc: 0.8046 - val_loss: 0.7954 - val_acc: 0.7030\n",
      "Epoch 8/10\n",
      "28000/28000 - 276s - loss: 0.4608 - acc: 0.8223 - val_loss: 0.8544 - val_acc: 0.7079\n",
      "Epoch 9/10\n",
      "28000/28000 - 274s - loss: 0.4198 - acc: 0.8408 - val_loss: 0.8871 - val_acc: 0.6964\n",
      "Epoch 10/10\n",
      "28000/28000 - 273s - loss: 0.3863 - acc: 0.8568 - val_loss: 0.9094 - val_acc: 0.7079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e601350>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model2.add(tf.keras.layers.Dropout(.5))\n",
    "model2.add(tf.keras.layers.Conv1D(64, 3, padding='valid', activation='relu', strides=1))\n",
    "model2.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model2.add(tf.keras.layers.LSTM(40))\n",
    "model2.add(tf.keras.layers.Dense(5))\n",
    "model2.add(tf.keras.layers.Activation('softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(training_padded, y[:28000], batch_size=30, epochs=10, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 - 209s - loss: 1.1665 - acc: 0.5615 - val_loss: 0.7924 - val_acc: 0.7040\n",
      "Epoch 2/5\n",
      "28000/28000 - 202s - loss: 0.7868 - acc: 0.6932 - val_loss: 0.7038 - val_acc: 0.7324\n",
      "Epoch 3/5\n",
      "28000/28000 - 202s - loss: 0.6521 - acc: 0.7462 - val_loss: 0.7174 - val_acc: 0.7317\n",
      "Epoch 4/5\n",
      "28000/28000 - 201s - loss: 0.5485 - acc: 0.7906 - val_loss: 0.7689 - val_acc: 0.7279\n",
      "Epoch 5/5\n",
      "28000/28000 - 211s - loss: 0.4498 - acc: 0.8319 - val_loss: 0.8105 - val_acc: 0.7201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18193e8d0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model2.add(tf.keras.layers.Dropout(.25))\n",
    "model2.add(tf.keras.layers.Conv1D(64, 7, padding='valid', activation='relu', strides=1))\n",
    "model2.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model2.add(tf.keras.layers.LSTM(30))\n",
    "model2.add(tf.keras.layers.Dense(5))\n",
    "model2.add(tf.keras.layers.Activation('softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(training_padded, y[:28000], batch_size=30, epochs=5, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 - 203s - loss: 1.2839 - acc: 0.5214 - val_loss: 1.1266 - val_acc: 0.6580\n",
      "Epoch 2/5\n",
      "28000/28000 - 195s - loss: 0.9832 - acc: 0.6421 - val_loss: 0.8259 - val_acc: 0.7089\n",
      "Epoch 3/5\n",
      "28000/28000 - 198s - loss: 0.8199 - acc: 0.6860 - val_loss: 0.7326 - val_acc: 0.7289\n",
      "Epoch 4/5\n",
      "28000/28000 - 203s - loss: 0.7166 - acc: 0.7241 - val_loss: 0.7089 - val_acc: 0.7260\n",
      "Epoch 5/5\n",
      "28000/28000 - 201s - loss: 0.6424 - acc: 0.7498 - val_loss: 0.7146 - val_acc: 0.7340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14cfcc510>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model3.add(tf.keras.layers.Dropout(.5))\n",
    "model3.add(tf.keras.layers.Conv1D(64, 7, padding='valid', activation='relu', strides=1))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model3.add(tf.keras.layers.LSTM(30))\n",
    "model3.add(tf.keras.layers.Dense(5))\n",
    "model3.add(tf.keras.layers.Activation('softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(training_padded, y[:28000], batch_size=64, epochs=5, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 - 163s - loss: 1.3742 - acc: 0.4724 - val_loss: 1.3207 - val_acc: 0.5049\n",
      "Epoch 2/5\n",
      "28000/28000 - 151s - loss: 1.1026 - acc: 0.6104 - val_loss: 0.9499 - val_acc: 0.6854\n",
      "Epoch 3/5\n",
      "28000/28000 - 151s - loss: 0.9544 - acc: 0.6443 - val_loss: 0.8625 - val_acc: 0.6986\n",
      "Epoch 4/5\n",
      "28000/28000 - 151s - loss: 0.8542 - acc: 0.6637 - val_loss: 0.7789 - val_acc: 0.7051\n",
      "Epoch 5/5\n",
      "28000/28000 - 152s - loss: 0.7699 - acc: 0.6991 - val_loss: 0.7457 - val_acc: 0.7174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x420df6c90>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model3.add(tf.keras.layers.Dropout(.5))\n",
    "model3.add(tf.keras.layers.Conv1D(64, 7, padding='valid', activation='relu', strides=1))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model3.add(tf.keras.layers.LSTM(30))\n",
    "model3.add(tf.keras.layers.Dense(5))\n",
    "model3.add(tf.keras.layers.Activation('softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(training_padded, y[:28000], batch_size=128, epochs=5, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 - 147s - loss: 0.7105 - acc: 0.7239 - val_loss: 0.7265 - val_acc: 0.7291\n",
      "Epoch 2/5\n",
      "28000/28000 - 153s - loss: 0.6549 - acc: 0.7457 - val_loss: 0.7250 - val_acc: 0.7273\n",
      "Epoch 3/5\n",
      "28000/28000 - 159s - loss: 0.6155 - acc: 0.7625 - val_loss: 0.7405 - val_acc: 0.7234\n",
      "Epoch 4/5\n",
      "28000/28000 - 152s - loss: 0.5752 - acc: 0.7817 - val_loss: 0.7847 - val_acc: 0.7206\n",
      "Epoch 5/5\n",
      "28000/28000 - 167s - loss: 0.5299 - acc: 0.7983 - val_loss: 0.7744 - val_acc: 0.7210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1400590>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(training_padded, y[:28000], batch_size=128, epochs=5, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 - 180s - loss: 1.3775 - acc: 0.4739 - val_loss: 1.2895 - val_acc: 0.5207\n",
      "Epoch 2/5\n",
      "28000/28000 - 173s - loss: 1.2592 - acc: 0.5605 - val_loss: 1.6116 - val_acc: 0.4760\n",
      "Epoch 3/5\n",
      "28000/28000 - 175s - loss: 1.3370 - acc: 0.4754 - val_loss: 1.1278 - val_acc: 0.6291\n",
      "Epoch 4/5\n",
      "28000/28000 - 174s - loss: 1.1985 - acc: 0.5691 - val_loss: 1.0574 - val_acc: 0.6597\n",
      "Epoch 5/5\n",
      "28000/28000 - 176s - loss: 1.1212 - acc: 0.6127 - val_loss: 0.9917 - val_acc: 0.6810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4247f6450>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = tf.keras.models.Sequential()\n",
    "model4.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model4.add(tf.keras.layers.Dropout(.5))\n",
    "model4.add(tf.keras.layers.Conv1D(64, 7, padding='valid', activation='relu', strides=1))\n",
    "model4.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model4.add(tf.keras.layers.LSTM(30, dropout=.5))\n",
    "model4.add(tf.keras.layers.Dense(5))\n",
    "model4.add(tf.keras.layers.Activation('softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model4.fit(training_padded, y[:28000], batch_size=128, epochs=5, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 - 173s - loss: 1.0516 - acc: 0.6340 - val_loss: 0.9259 - val_acc: 0.6930\n",
      "Epoch 2/5\n",
      "28000/28000 - 179s - loss: 0.9974 - acc: 0.6476 - val_loss: 0.8961 - val_acc: 0.6980\n",
      "Epoch 3/5\n",
      "28000/28000 - 172s - loss: 0.9788 - acc: 0.6521 - val_loss: 0.9221 - val_acc: 0.6961\n",
      "Epoch 4/5\n",
      "28000/28000 - 166s - loss: 0.9556 - acc: 0.6560 - val_loss: 0.8825 - val_acc: 0.7004\n",
      "Epoch 5/5\n",
      "28000/28000 - 180s - loss: 0.9101 - acc: 0.6626 - val_loss: 0.8490 - val_acc: 0.7006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x420e25550>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(training_padded, y[:28000], batch_size=128, epochs=5, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 - 219s - loss: 1.1018 - acc: 0.5828 - val_loss: 0.7832 - val_acc: 0.7101\n",
      "Epoch 2/5\n",
      "28000/28000 - 214s - loss: 0.7848 - acc: 0.6919 - val_loss: 0.6957 - val_acc: 0.7349\n",
      "Epoch 3/5\n",
      "28000/28000 - 207s - loss: 0.6992 - acc: 0.7243 - val_loss: 0.7031 - val_acc: 0.7363\n",
      "Epoch 4/5\n",
      "28000/28000 - 186s - loss: 0.6472 - acc: 0.7450 - val_loss: 0.7132 - val_acc: 0.7354\n",
      "Epoch 5/5\n",
      "28000/28000 - 200s - loss: 0.6092 - acc: 0.7602 - val_loss: 0.7234 - val_acc: 0.7309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x42745ffd0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = tf.keras.models.Sequential()\n",
    "model5.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model5.add(tf.keras.layers.Dropout(.5))\n",
    "model5.add(tf.keras.layers.Conv1D(64, 7, padding='valid', activation='relu', strides=1))\n",
    "model5.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model5.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(30, dropout=.5)))\n",
    "model5.add(tf.keras.layers.Dense(5))\n",
    "model5.add(tf.keras.layers.Activation('softmax'))\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model5.fit(training_padded, y[:28000], batch_size=128, epochs=5, validation_data=(test_padded, y[28000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"ultra_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = []\n",
    "for i, x in enumerate(data2[\"stars_2.0\"]):\n",
    "    if x == 1:\n",
    "        data_balanced.append((data2[\"text\"][i], [0,1,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, x in enumerate(data2[\"stars_1.0\"]):\n",
    "    if x == 1 and count < 2500:\n",
    "        data_balanced.append((data2[\"text\"][i], [1,0,0,0,0]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, x in enumerate(data2[\"stars_3.0\"]):\n",
    "    if x == 1 and count < 2500:\n",
    "        data_balanced.append((data2[\"text\"][i], [0,0,1,0,0]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, x in enumerate(data2[\"stars_4.0\"]):\n",
    "    if x == 1 and count < 2500:\n",
    "        data_balanced.append((data2[\"text\"][i], [0,0,0,1,0]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, x in enumerate(data2[\"stars_5.0\"]):\n",
    "    if x == 1 and count < 2500:\n",
    "        data_balanced.append((data2[\"text\"][i], [0,0,0,0,1]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12492"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced = [str(i[0]) for i in data_balanced]\n",
    "y_balanced = [i[1] for i in data_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_balanced = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token=\"<UNK>\")\n",
    "tokenizer_balanced.fit_on_texts(X_balanced[:10000])\n",
    "\n",
    "training_sequences = tokenizer_balanced.texts_to_sequences(X_balanced[:10000])\n",
    "training_padded = tf.keras.preprocessing.sequence.pad_sequences(training_sequences, maxlen=200, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "test_sequences = tokenizer_balanced.texts_to_sequences(X_balanced[10000:])\n",
    "test_padded = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2492 samples\n",
      "Epoch 1/5\n",
      "10000/10000 - 79s - loss: 1.5412 - acc: 0.2827 - val_loss: 1.3152 - val_acc: 0.3929\n",
      "Epoch 2/5\n",
      "10000/10000 - 65s - loss: 1.1513 - acc: 0.5045 - val_loss: 1.0802 - val_acc: 0.5353\n",
      "Epoch 3/5\n",
      "10000/10000 - 65s - loss: 0.9848 - acc: 0.5858 - val_loss: 1.0771 - val_acc: 0.5401\n",
      "Epoch 4/5\n",
      "10000/10000 - 78s - loss: 0.8847 - acc: 0.6332 - val_loss: 1.0983 - val_acc: 0.5305\n",
      "Epoch 5/5\n",
      "10000/10000 - 70s - loss: 0.8224 - acc: 0.6632 - val_loss: 1.1296 - val_acc: 0.5361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x44d6e24d0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = tf.keras.models.Sequential()\n",
    "model5.add(tf.keras.layers.Embedding(5000, 200, input_length=200))\n",
    "model5.add(tf.keras.layers.Dropout(.5))\n",
    "model5.add(tf.keras.layers.Conv1D(64, 7, padding='valid', activation='relu', strides=1))\n",
    "model5.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model5.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(30, dropout=.5)))\n",
    "model5.add(tf.keras.layers.Dense(5))\n",
    "model5.add(tf.keras.layers.Activation('softmax'))\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model5.fit(training_padded, y_balanced[:10000], batch_size=128, epochs=5, validation_data=(test_padded, y_balanced[10000:]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
