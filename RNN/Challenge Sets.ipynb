{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import models\n",
    "import importlib\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from matplotlib import pyplot as plt\n",
    "K = tf.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/Users/varun/School/CS182/finalproj/CS182-Spring2020-NLP-Project/models.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset-binary.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:int(len(df) * .8)]\n",
    "test_df = df.iloc[int(len(df) * .8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(y_true, y_pred):\n",
    "        return K.sum(K.cast(K.equal(K.argmax(y_true), K.argmax(y_pred)), dtype = tf.int32)) / 32\n",
    "\n",
    "def distance(y_true, y_pred):\n",
    "        total_corr = K.sum(K.cast(K.equal(K.argmax(y_true), K.argmax(y_pred)), dtype = tf.int32))\n",
    "        return K.sum(K.cast(K.abs(K.argmax(y_true) - K.argmax(y_pred)), dtype = tf.int32)) / (32 - total_corr)\n",
    "    \n",
    "def sum_metrics(y_true, y_pred):\n",
    "        acc = (32 - K.sum(K.cast(K.equal(K.argmax(y_true), K.argmax(y_pred)), dtype = tf.int32))) / 32\n",
    "        total_corr = K.sum(K.cast(K.equal(K.argmax(y_true), K.argmax(y_pred)), dtype = tf.int32))\n",
    "        return acc + K.sum(K.cast(K.abs(K.argmax(y_true) - K.argmax(y_pred)), dtype = tf.int32)) / (32 - total_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_metric_on_set(tokenizer, test_reviews, test_stars, model, model_or_func = True):\n",
    "    test_padded = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test_reviews), maxlen = 250, padding = 'post', truncating = 'post')\n",
    "    pred = None\n",
    "    if model_or_func:\n",
    "        pred = model.predict(test_padded)\n",
    "    else:\n",
    "        pred = model(test_padded)\n",
    "    corr = 0\n",
    "    dist_sum = 0\n",
    "    for i in range(len(test_stars)):\n",
    "        if np.argmax(pred[i]) == np.argmax(test_stars[i]):\n",
    "            corr += 1\n",
    "        else:\n",
    "            dist_sum += np.abs(np.argmax(pred[i]) - np.argmax(test_stars[i]))\n",
    "    print(corr / len(test_stars))\n",
    "    print(dist_sum / (len(test_stars) - corr))\n",
    "    print(((dist_sum / (len(test_stars) - corr)) / 4) + 1 - (corr / len(test_stars)))\n",
    "    print((dist_sum / (len(test_stars) - corr)) + 1 - (corr / len(test_stars)))\n",
    "    return pred, test_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_5 = pd.read_csv(\"challenge_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_6 = pd.read_csv(\"challenge_6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 5000, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(train_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"conc.h5\", \n",
    "                                            custom_objects = {'custom_accuracy' : custom_accuracy, \n",
    "                                                             'distance' : distance,\n",
    "                                                             'sum_metrics' : sum_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stars = []\n",
    "for i in challenge_5[\"stars\"]:\n",
    "    temp = [0, 0, 0, 0, 0]\n",
    "    temp[int(i - 1)] = 1\n",
    "    test_stars.append(np.array(temp))\n",
    "test_stars = np.array(test_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.084\n",
      "1.2882096069868996\n",
      "1.238052401746725\n",
      "2.2042096069868995\n"
     ]
    }
   ],
   "source": [
    "pred, true = sum_metric_on_set(tokenizer, challenge_5[\"text\"], test_stars, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0-1': (0, 0),\n",
       "  '0-2': (0, 0),\n",
       "  '0-3': (0, 0),\n",
       "  '0-4': (0, 0),\n",
       "  '1-0': (226, 0.6792154084000968),\n",
       "  '1-2': (61, 0.38608986774428944),\n",
       "  '1-3': (38, 0.43303837509531723),\n",
       "  '1-4': (33, 0.5913599792755011),\n",
       "  '2-0': (0, 0),\n",
       "  '2-1': (0, 0),\n",
       "  '2-3': (0, 0),\n",
       "  '2-4': (0, 0),\n",
       "  '3-0': (0, 0),\n",
       "  '3-1': (0, 0),\n",
       "  '3-2': (0, 0),\n",
       "  '3-4': (0, 0),\n",
       "  '4-0': (0, 0),\n",
       "  '4-1': (0, 0),\n",
       "  '4-2': (0, 0),\n",
       "  '4-3': (0, 0)},\n",
       " {'0': 0, '1': 500, '2': 0, '3': 0, '4': 0})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.get_most_confused(pred, true, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
